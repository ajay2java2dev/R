par(cex = 0.5)
corrplot(cor_df, method="pie",type="lower",order="original")
cex.before <- par("cex")
par(cex = 0.5)
corrplot(cor_df, method="pie",type="lower",order="AOE")
cex.before <- par("cex")
par(cex = 0.5)
corrplot(cor_df, method="pie",type="upper",order="AOE")
round(cor_coeff_salePrice_df %>% select(-cor_coeff_selected_names), 2)
t(sort( round(cor_coeff_salePrice_df %>% select(-cor_coeff_selected_names), 2), decreasing = F ))
t(sort( round(cor_coeff_salePrice_df.sub,2) decreasing = T))
t(sort( round(cor_coeff_salePrice_df.sub, 2) decreasing = T))
cor_coeff_salePrice_df.sub
round(cor_coeff_salePrice_df.sub, 2)
t(sort(round(cor_coeff_salePrice_df.sub, 2), decreasing = T))
10 ^ seq(10,-2, length=100)
regfit.full = regsubsets (Sale_Price ~., data = data.frame(Sale_Price=data$Sale_Price,selected_df), method=c("exhaustive"), really.big = T)
rs = summary(regfit.full)
rs$which
train.x <- read.csv("train.csv")
train.x <- read.csv("train.csv")
test.x <- read.csv("test.csv")
train.x$PID
selected_df[train.x$PID,]
train.x[!train.x$PID %in% selected_df$PID]
train.x[!train.x %in% selected_df]
train.x
train.x <- read.csv("train.csv")
train.x
train.x[!train.x %in% selected_df]
selected_df
selected_df_with_pid = data.frame(data$PID, selected_df_with_pid)
selected_df_with_pid = data.frame(data$PID, selected_df)
selected_df_with_pid
selected_df_with_pid = data.frame(PID=data$PID, selected_df)
train.x[!train.x$PID %in% selected_df_with_pid$PID]
train.x
train.x <- read.csv("train.csv")
train.x
selected_df_with_pid[!selected_df_with_pid$PID %in% train.x$PID]
selected_df_with_pid = data.frame(PID=data$PID, selected_df)
selected_df_with_pid[!selected_df_with_pid$PID %in% train.x$PID]
selected_df_with_pid$PID
train.x$PID
!selected_df_with_pid$PID %in% train.x$PID
selected_df_with_pid[!selected_df_with_pid$PID %in% train.x$PID]
train.x <- read.csv("train.csv")
dmy <- dummyVars("~ .", data = data[,cat.cols], fullRank = T)
df <- data.frame(predict(dmy, newdata = data)) # this will now have 309 variables.
df <- data.frame(df, data[, numeric.cols])
train.x <- read.csv("train.csv")
dmy <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df <- data.frame(predict(dmy, newdata = train.x)) # this will now have 309 variables.
df <- data.frame(df, train.x[, numeric.cols])
mypackages = c("tidyverse", "dplyr", "reshape2", "glmnet","gbm", "xgboost", "ggplot2", "caret","randomForest", "leaps", "corrplot")
tmp = setdiff(mypackages, rownames(installed.packages()))
if (length(tmp) > 0) install.packages(tmp)
library(tidyverse)
library(dplyr)
library(reshape2)
library(glmnet)
library(gbm)
library(xgboost)
library(ggplot2)
library(caret)
library(randomForest)
library (leaps)
library (corrplot)
rm (list=ls())
data = read.csv("Ames_data.csv")
testIDs <- read.table("project1_testIDs.dat")
set.seed(1234)
numeric.cols <- names(data[, sapply(data, is.numeric)])
na_cols <- names(which(colSums(is.na(data)) > 0))
data[is.na(data)] = 0
cat.cols <- names(data)[!(names(data) %in%  numeric.cols)]
# convert categorical to numerical
dmy <- dummyVars("~ .", data = data[,cat.cols], fullRank = T)
df <- data.frame(predict(dmy, newdata = data)) # this will now have 309 variables.
df <- data.frame(df, data[, numeric.cols])
# http://www.r-tutor.com/elementary-statistics/numerical-measures/correlation-coefficient
# https://www.statmethods.net/stats/correlations.html
x = df$Sale_Price
remove.var <- c ("PID", "Sale_Price")
y = df %>% select(-remove.var)
cov_salePrice <- cov (x, y)
cor_coeff_salePrice <- cor (x, y)
cor_coeff_salePrice_df <- as.data.frame(cor_coeff_salePrice)
# Closer to 0 - not relevant, Closer to 1 - relevant
cor_coeff_salePrice_df.sub <- cor_coeff_salePrice_df[colSums(cor_coeff_salePrice > 0.25 | cor_coeff_salePrice < -0.25) > 0]
cor_coeff_selected_names <- names(cor_coeff_salePrice_df.sub)
# relevant list
t(sort(round(cor_coeff_salePrice_df.sub, 2), decreasing = T))
t(sort( round(cor_coeff_salePrice_df %>% select(-cor_coeff_selected_names), 2), decreasing = F ))
selected_df <- df[, cor_coeff_selected_names]
cor_df <- cor(selected_df)
cex.before <- par("cex")
par(cex = 0.5)
corrplot(cor_df, method="pie",type="upper",order="AOE")
cex.before <- par("cex")
par(cex = 0.5)
corrplot(cor_df, method="pie",type="lower",order="AOE")
### Also lets try regsubsets
regfit.full = regsubsets (Sale_Price ~., data = data.frame(Sale_Price=data$Sale_Price,selected_df), method=c("exhaustive"), really.big = T)
rs = summary(regfit.full)
rs$which
train.x <- read.csv("train.csv")
dmy <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df <- data.frame(predict(dmy, newdata = train.x)) # this will now have 309 variables.
df <- data.frame(df, train.x[, numeric.cols])
test.x <- read.csv("test.csv")
dmy.test.x <- dummyVars("~ .", data = test.x[,cat.cols], fullRank = T)
df.test.x <- data.frame(predict(dmy.test.x, newdata = data)) # this will now have 309 variables.
df.test.x <- data.frame(df.test.x, data[, numeric.cols])
df.train.x[, cor_coeff_selected_names]
train.x <- read.csv("train.csv")
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols])
df.train.x[, cor_coeff_selected_names]
train.x <- read.csv("train.csv")
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols])
df.train.x <- df.train.x[, cor_coeff_selected_names]
test.x <- read.csv("test.csv")
dmy.test.x <- dummyVars("~ .", data = test.x[,cat.cols], fullRank = T)
df.test.x <- data.frame(predict(dmy.test.x, newdata = data)) # this will now have 309 variables.
df.test.x <- data.frame(df.test.x, data[, numeric.cols])
df.test.x <- df.test.x[, cor_coeff_selected_names]
df.test.x
# 1. filtered out the 59 variables we need
train.x <- read.csv("train.csv")
train.y <- log(train.x$Sale_Price)
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols])
df.train.x <- df.train.x[, cor_coeff_selected_names]
test.x <- read.csv("test.csv")
test.PID <- test.x$PID
dmy.test.x <- dummyVars("~ .", data = test.x[,cat.cols], fullRank = T)
df.test.x <- data.frame(predict(dmy.test.x, newdata = data)) # this will now have 309 variables.
df.test.x <- data.frame(df.test.x, data[, numeric.cols])
df.test.x <- df.test.x[, cor_coeff_selected_names]
lam.seq = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet(train.x, train.y, alpha=1, lambda=lam.seq)
train.y
train.x
df.train.x
lasso.model = glmnet(df.train.x, train.y, alpha=1, lambda=lam.seq)
df.train.x
as.matrix(df.train.x)
lasso.model = glmnet( as.matrix(df.train.x), train.y, alpha=1, lambda=lam.seq)
library(glmnet)
library(ISLR)
attach(Hitters)
x = model.matrix(Salary~., Hitters)[,-1]
y = Hitters[row.names(x),]$Salary
set.seed(1)
train = sample(1:nrow(x), nrow(x)*0.75)
test = (-train)
y.test = y[test]
# values of lambdas to use
grid = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet(x[train,], y[train], alpha=1, lambda=grid)
plot(lasso.model)
# Using Cross Validation to find the best lambda
lasso_cv_model =cv.glmnet(x[train,], y[train], alpha=1, lambda=grid)
plot(lasso_cv_model)
best_lambda = lasso_cv_model$lambda.min
best_lambda
pred = predict(lasso.model, s=best_lambda, newx=x[test,])
mean((pred-y.test)^2)
lasso.coef = predict(lasso.model, type="coefficient", s=best_lambda)[1:20,]
lasso.coef[lasso.coef!=0]
# only non-zero coefficients
x
train.x <- read.csv("train.csv")
train.y <- log(train.x$Sale_Price)
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy.train.x, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols])
df.train.x <- df.train.x[, cor_coeff_selected_names]
df.train.x
df.train.x
as.matrix(df.train.x)
as.matrix(train.y)
lam.seq = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1, lambda=lam.seq)
x
train = sample(1:nrow(x), nrow(x)*0.75)
train
x[train,]
y[train]
x
as.matrix(df.train.x)
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
names(df.train.x)
class(df.train.x)
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols], stringsAsFactors = FALSE)
df.train.x
df.train.x <- df.train.x[, cor_coeff_selected_names]
df.train.x
train.x <- read.csv("train.csv")
train.y <- log(train.x$Sale_Price)
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy.train.x, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols], stringsAsFactors = FALSE)
df.train.x <- df.train.x[, cor_coeff_selected_names]
df.train.x
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
df.test.x
train.y
x = model.matrix(Salary~., Hitters)[,-1]
x
model.matrix(Salary~., Hitters)
train.x <- read.csv("train.csv")
train.y <- log(train.x$Sale_Price)
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy.train.x, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols], stringsAsFactors = FALSE)
df.train.x <- df.train.x[, cor_coeff_selected_names]
lam.seq = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
df.train.x <- model.matrix( ~ ., df.train.x)
df.train.x
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
numeric.cols <- names(train.x[, sapply(train.x, is.numeric)])
na_cols <- names(which(colSums(is.na(train.x)) > 0))
data[is.na(data)] = 0
na_cols
train.x <- read.csv("train.csv")
numeric.cols <- names(train.x[, sapply(train.x, is.numeric)])
na_cols <- names(which(colSums(is.na(train.x)) > 0))
train.x[is.na(data)] = 0
train.x <- read.csv("train.csv")
numeric.cols <- names(train.x[, sapply(train.x, is.numeric)])
na_cols <- names(which(colSums(is.na(train.x)) > 0))
train.x[is.na(train.x)] = 0
train.y <- log(train.x$Sale_Price)
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy.train.x, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols], stringsAsFactors = FALSE)
df.train.x <- df.train.x[, cor_coeff_selected_names]
df.train.x <- model.matrix( ~ ., df.train.x)
lam.seq = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
# 1. filtered out the 59 variables we need
train.x <- read.csv("train.csv")
numeric.cols <- names(train.x[, sapply(train.x, is.numeric)])
na_cols <- names(which(colSums(is.na(train.x)) > 0))
train.x[is.na(train.x)] = 0
train.y <- log(train.x$Sale_Price)
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy.train.x, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols], stringsAsFactors = FALSE)
df.train.x <- df.train.x[, cor_coeff_selected_names]
lam.seq = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
# https://stats.stackexchange.com/questions/283952/lasso-and-dimension-reduction
# 1. filtered out the 59 variables we need
train.x <- read.csv("train.csv")
train.x[is.na(train.x)] = 0
train.y <- log(train.x$Sale_Price)
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy.train.x, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols], stringsAsFactors = FALSE)
df.train.x <- df.train.x[, cor_coeff_selected_names]
#df.train.x <- model.matrix( ~ ., df.train.x)
lam.seq = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
test.x <- read.csv("test.csv")
test.x[is.na(test.x)] = 0
test.PID <- test.x$PID
dmy.test.x <- dummyVars("~ .", data = test.x[,cat.cols], fullRank = T)
df.test.x <- data.frame(predict(dmy.test.x, newdata = data)) # this will now have 309 variables.
df.test.x <- data.frame(df.test.x, data[, numeric.cols])
df.test.x <- df.test.x[, cor_coeff_selected_names]
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols])
df.train.x <- data.frame(predict(dmy.train.x, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols])
df.train.x <- df.train.x[, cor_coeff_selected_names]
dmy.train.x <- dummyVars("~ .", data = train.x, fullRank = T)
dmy.train.x
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
train.x <- read.csv("train.csv")
train.x[is.na(train.x)] = 0
train.y <- log(train.x$Sale_Price)
dmy.train.x <- dummyVars("~ .", data = train.x[,cat.cols], fullRank = T)
df.train.x <- data.frame(predict(dmy.train.x, newdata = train.x)) # this will now have 309 variables.
df.train.x <- data.frame(df.train.x, train.x[, numeric.cols])
df.train.x <- df.train.x[, cor_coeff_selected_names]
lam.seq = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
test.PID <- test.x$PID
dmy.test.x <- dummyVars("~ .", data = test.x[,cat.cols], fullRank = T)
df.test.x <- data.frame(predict(dmy.test.x, newdata = data)) # this will now have 309 variables.
df.test.x <- data.frame(df.test.x, data[, numeric.cols])
df.test.x <- df.test.x[, cor_coeff_selected_names]
df.test.x
lasso.model
summary(lasso.model)
lam.seq = 10 ^ seq(10,-2, length=100)
lasso.model = glmnet( as.matrix(df.train.x), as.matrix(train.y), alpha=1)
lasso_cv_model =cv.glmnet(as.matrix(df.train.x), as.matrix(train.y), alpha=1, lambda=lam.seq)
best_lambda = lasso_cv_model$lambda.min
best_lambda
best_lambda
pred = predict(lasso.model, s=best_lambda, newx=df.test.x)
test.PID <- test.x$PID
dmy.test.x <- dummyVars("~ .", data = test.x[,cat.cols], fullRank = T)
df.test.x <- data.frame(predict(dmy.test.x, newdata = data)) # this will now have 309 variables.
df.test.x <- data.frame(df.test.x, data[, numeric.cols])
df.test.x <- df.test.x[, cor_coeff_selected_names]
pred = predict(lasso.model, s=best_lambda, newx=df.test.x)
pred = predict(lasso.model, s=best_lambda, newx=as.matrix(df.test.x))
mean((pred-y.test)^2)
pred-y.test
lasso.coef = predict(lasso.model, type="coefficient", s=best_lambda)[1:20,]
lasso.coef[lasso.coef!=0]
pred = predict(lasso.model, s=best_lambda, newx=as.matrix(df.test.x))
lasso.coef = predict(lasso.model, type="coefficient", s=best_lambda)
lasso.coef[lasso.coef!=0]
lasso.coef[lasso.coef!=0]
lasso.coef = predict(lasso.model, type="coefficient", s=best_lambda)[1:20,]
lasso.coef
predict(lasso.model, type="coefficient", s=best_lambda)
lasso.coef = predict(lasso.model, type="coefficient", s=best_lambda)[1:30,]
lasso.coef[lasso.coef!=0]
lasso.coef = predict(lasso.model, type="coefficient", s=best_lambda)[1:60,]
lasso.coef[lasso.coef!=0]
lasso.coef = predict(lasso.model, type="coefficient", s=best_lambda)[1:100,]
lasso.coef = predict(lasso.model, type="coefficient", s=best_lambda)[1:60,]
lasso.coef[lasso.coef!=0]
t(lasso.coef[lasso.coef!=0])
lasso.coef[lasso.coef!=0]
lasso.coef[lasso.coef!=0]
t(lasso.coef[lasso.coef!=0])
lasso.coef[lasso.coef!=0][1,]
t(lasso.coef[lasso.coef!=0])[1]
t(lasso.coef[lasso.coef!=0])[1,]
t(lasso.coef[lasso.coef!=0])[,1]
data.frame(lasso.coef[lasso.coef!=0])
round(data.frame(lasso.coef[lasso.coef!=0]),2)
sort(round(data.frame(lasso.coef[lasso.coef!=0]),2))
sort(round(data.frame(lasso.coef[lasso.coef!=0]),2), decreasing = T)
round(data.frame(lasso.coef[lasso.coef!=0]),2)
round(data.frame(lasso.coef[lasso.coef!=0]),2)[,1]
round(data.frame(lasso.coef[lasso.coef!=0]),2)[,2]
round(data.frame(lasso.coef[lasso.coef!=0]),2)
round(data.frame(coeff=lasso.coef[lasso.coef!=0]),2)
round(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0]),2)
round(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0]),5)
round(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0]),5)$lasso_coeff
sort(round(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0]),5)$lasso_coeff, decreasing = T)
sort(round(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0]),5), decreasing = T)
round(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0]),5), decreasing = T
round(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0]),5)
round(as.matrix(lasso_coeff=lasso.coef[lasso.coef!=0]),5)
as.matrix(lasso_coeff=lasso.coef[lasso.coef!=0])
as.matrix(lasso_coeff=lasso.coef[lasso.coef!=0])
as.matrix(lasso_coeff=lasso.coef[lasso.coef!=0])
round(as.matrix(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0])),5)
sort(round(as.matrix(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0])),5))
round(as.matrix(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0])),5)
names(lasso.coef)
sort(names(lasso.coef))
summary(data)
lasso.coef
round(as.matrix(data.frame(lasso_coeff=lasso.coef[lasso.coef!=0])),5)
knitr::opts_chunk$set(echo = TRUE)
lo.lev <- function(x1, sp){
# x1: n-by-1 feature vector
# sp: a numerical value for "span"
n = length(x1);
lev = rep(0, n)
##############################################
# YOUR CODE: Compute the diagonal entries of the
#            smoother matrix S and
#            store it in a vector "lev"
# Tip: check how we compute the smoother matrix
#      for smoothing spline models
##############################################
for (i in 1:n) {
y = rep(0, n);
y[i]=1;
f.lev = loess(y ~ x1, data.frame(x = x1, y = y), span=sp,
control=loess.control(surface = "direct"))
lev[i] = f.lev$fitted[i]
}
return(lev)
}
onestep_CV <- function(x1, y1, sp){
##############################################
#  YOUR CODE:
#  1) Fit a loess model y1 ~ x1 with span = sp, and extract
#     the corresponding residual vector
n = length(x1)
f.cv = loess(y1 ~ x1, data.frame(x = x1, y = y1), span=sp,
control=loess.control(surface = "direct"))
residuals = f.cv$residuals
#  2) Call lo.lev to obtain the diagonal entries of S
lev = lo.lev(x1, sp)
#  3) Compute LOO-CV and GCV using formula from lecture notes
#    [lec_W5_NonlinearRegression.pdf] page 33.
cv = (sum((residuals / (1 - lev)) ^2))/n
gcv = (sum((residuals / (1 - sum(lev)/n))^2))/n
##############################################
return(list(cv = cv, gcv = gcv))
}
myCV <- function(x1, y1, span){
# x1: feature vector of length n
# y1: response vector of length n
# span: a sequence of values for "span"
m = length(span)
cv = rep(0, m)
gcv = rep(0, m)
for(i in 1:m){
tmp = onestep_CV(x1, y1, span[i])
cv[i] = tmp$cv
gcv[i] = tmp$gcv
}
return(list(cv = cv, gcv = gcv))
}
mydata = read.csv(file = "Coding3_Data.csv")
dim(X)
library(MASS)
#help(lda)
#help(qda)
# 40 samples from each class, totally 400 training data and 400 test data
load('digits.Rdata')
setwd("~/source/uiuc/CS598_PSL/cs598_psl_team_codebase/ajay/samples")
library(MASS)
#help(lda)
#help(qda)
# 40 samples from each class, totally 400 training data and 400 test data
load('digits.Rdata')
dim(X)
View(X)
View(Xtest)
dim(Xtest)
table(Y)
library(MASS)
#help(lda)
#help(qda)
# 40 samples from each class, totally 400 training data and 400 test data
load('digits.Rdata')
dim(X)
table(Ytest)
dig.lda = lda(X,Y);
Ytest.pred = predict(dig.lda, Xtest)$class
table(Ytest, Ytest.pred)
X
View(X)
View(Xtest)
sum(Ytest != Ytest.pred)
View(X)
qda(X,Y)
library(MASS)
#help(lda)
#help(qda)
# 40 samples from each class, totally 400 training data and 400 test data
load('digits.Rdata')
dim(X)
dim(Xtest)
table(Y)
table(Ytest)
dig.lda = lda(X,Y);
Ytest.pred = predict(dig.lda, Xtest)$class
table(Ytest, Ytest.pred)
sum(Ytest != Ytest.pred)
qda(X,Y)
library(MASS)
#help(lda)
#help(qda)
# 40 samples from each class, totally 400 training data and 400 test data
load('digits.Rdata')
dim(X)
dim(Xtest)
table(Y)
table(Ytest)
dig.lda = lda(X,Y);
Ytest.pred = predict(dig.lda, Xtest)$class
table(Ytest, Ytest.pred)
sum(Ytest != Ytest.pred)
dig.qda = qda(X,Y)
FDA.dir = dig.lda$scaling
FDA.dir = dig.lda$scaling
FDA.dir
dim(FDA.dir)  # at most 10-1 = 9 directions
X
dim(X)
dim(FDA.dir)  # at most 10-1 = 9 directions
dim(X)
F = X %*% FDA.dir; # multiply matrix (400 * 256) x (256 * 9)
F
par(mfrow=c(1,2))
plot(F[,1],F[,2], type="n", xlab="", ylab="");
text(F[,1], F[,2], Y, col=Y+1);
plot(F[,1],F[,2], type="n", xlab="", ylab="");
text(F[,1], F[,2], Y, col=Y+1);
Ftest = Xtest%*%dig.lda$scaling;
Ftest
plot(Ftest[,1], Ftest[,2], type="n", xlab="", ylab="");
plot(Ftest[,1], Ftest[,2], type="n", xlab="", ylab="");
text(Ftest[,1], Ftest[,2], Ytest, col=Ytest+1);
Ftest = Xtest%*% FDA.dir;
plot(Ftest[,1], Ftest[,2], type="n", xlab="", ylab="");
text(Ftest[,1], Ftest[,2], Ytest, col=Ytest+1);
Ftest = Xtest%*% FDA.dir;
plot(Ftest[,1], Ftest[,2], type="n", xlab="", ylab="");
text(Ftest[,1], Ftest[,2], Ytest, col=Ytest+1);
