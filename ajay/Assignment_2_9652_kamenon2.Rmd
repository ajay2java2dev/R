---
title: "Assignment_2_9652_kamenon2"
date: "2/20/2021"
output: html_document
---

```
Team:
- Mriganka
- Kai
- Kalathil Ajay Menon
```

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

### Coding 2: Implement Lasso using the Coordinate Descent (CD) algorithm and test your algorithm on the Boston housing data.

### Package installation
```{r}
mypackages = c("MASS", "glmnet")   # required packages
tmp = setdiff(mypackages, rownames(installed.packages()))  # packages need to be installed
if (length(tmp) > 0) install.packages(tmp)
lapply(mypackages, require, character.only = TRUE)
set.seed(9652)
```

```
1. MEDV (Y)  Median value of owner-occupied homes in $1000's (response variable)
2. CRIM      per capita crime rate by town
3. ZN        proportion of residential land zoned for lots over 
             25,000 sq.ft.
4. INDUS     proportion of non-retail business acres per town
5. CHAS      Charles River dummy variable (= 1 if tract bounds 
             river; 0 otherwise)
6. NOX       nitric oxides concentration (parts per 10 million)
7. RM        average number of rooms per dwelling
8. AGE       proportion of owner-occupied units built prior to 1940
9. DIS       weighted distances to five Boston employment centres
10. RAD       index of accessibility to radial highways
11. TAX      full-value property-tax rate per $10,000
12. PTRATIO  pupil-teacher ratio by town
13. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks 
             by town
14. LSTAT    % lower status of the population
```

### First, load the transformed Boston Housing Data, Coding2 myData.csv.

```{r}
rm(list=ls())
library(MASS)
myData = Boston
names(myData)[14] = "Y"
iLog = c(1, 3, 5, 6, 8, 9, 10, 14);
myData[, iLog] = log(myData[, iLog]);
myData[, 2] = myData[, 2] / 10;
myData[, 7] = myData[, 7]^2.5 / 10^4
myData[, 11] = exp(0.4 * myData[, 11]) / 1000;
myData[, 12] = myData[, 12] / 100;
myData[, 13] = sqrt(myData[, 13]);
write.csv(myData, file = "Coding2_myData.csv", 
          row.names = FALSE)

# After preparing the dataset, remove all objects and the attached MASS library
rm(list=objects())  
detach("package:MASS")

myData = read.csv("Coding2_myData.csv")
X = as.matrix(myData[, -14])
y = myData$Y
dim(X)
```


###  Write your own function MyLasso to implement CD, which should output estimated Lasso coefficients similar to the ones returned by R with option “standardized = TRUE”.

```{r}
one_var_lasso = function(r, x, lam) {
    xx = sum(x^2)
    xr = sum(r * x)
    b = (abs(xr) - lam/2)/xx
    b = sign(xr) * ifelse(b > 0, b, 0)
    return(b)
}
```


```{r}
MyLasso = function(X, y, lam.seq, maxit = 500) {
    
    # X: n-by-p design matrix without the intercept 
    # y: n-by-1 response vector 
    # lam.seq: sequence of lambda values 
    # maxit: number of updates for each lambda 
    # Center/Scale X
    # Center y
  
    if (!exists("lam.seq") || length(lam.seq) == 0) {lam.seq = exp(seq (-1,-8,length.out = 80) )}
    if (!exists("maxit")) {maxit = 100}
    n = length(y)
    p = dim(X)[2]
    nlam = length(lam.seq)

    ##############################
    # YOUR CODE: 
    # Record the corresponding means and scales
    # For example, 
    # y.mean = mean(y)
    # Xs = centered and scaled X
    ##############################
    y.mean = mean(y)
    X.mean <- colMeans(X)
    
    #auto implementation using scale. sweep() and apply() can also help
    #Xs = scale(X, center = TRUE, scale = TRUE)
    
    #manual implementation instead of scale function above
    Xs = matrix(nrow = dim(X)[1], ncol = dim(X)[2])
    colMean = NA;
    colSd = NA;
    for (j in 1:dim(X)[2]) { 
      colMean[j] = mean(X[, j])
      colSd[j] = sd (X[, j]) * sqrt ((n-1) /n)
      for (i in 1:dim(X)[1]) {
        Xs[i,j] = (X[i,j] - colMean[j]) / colSd[j]
      }
    }
    attr(Xs,"center")=colMean
    attr(Xs,"scale")=colSd
    attributes(Xs)

    # Initilize coef vector b and residual vector r
    b = rep(0, p)
    r = y
    B = matrix(nrow = nlam, ncol = p + 1) # empty matrix
    
    # Triple nested loop
    for (m in 1:nlam) {
        lam = 2 * n * lam.seq[m]
        for (step in 1:maxit) {
            for (j in 1:p) {
                r = r + (Xs[, j] * b[j])
                b[j] = one_var_lasso(r, Xs[, j], lam)
                r = r - Xs[, j] * b[j]
            }
        }
        #print(c(0, b))
        B[m, ] = c(0, b)
    }
   
    ##############################
    # YOUR CODE:
    # Scale back the coefficients;
    # Update the intercepts stored in B[, 1]
    ##############################
    dim (B)
    dim (X)
    dim (Xs)
    p
    #B = unscale(B, Xs, c(1:13)) # FIXME: check if unscale function can be implemented
    #B = t(apply(B, 1,  function(r) r * attr(Xs, 'scale') +  attr(Xs, 'center'))) 
    
    # Tried this below from piazza notes
    for (i in 1:nrow(B)) {
      Bx = 0
      for (j in 1:p) {
        Bj = j + 1
        B[i,Bj] = B[i,Bj] / (sd(X[,j]) * sqrt ((n-1) /n))
        Bx = Bx + mean (X[,j]) * B[i,Bj]
      }
      intercept = y.mean - Bx
      B[i,1] = intercept
    }
    
    attributes(Xs);
    #B[, 2:14] <- B[, 2:14] %*% diag(1.0 / (attr(Xs, 'scaled:scale')) )
    #B[, 1] <- y.mean - B[, 2:14] %*% X.mean
    
    #B[, 2:14] <- B[, 2:14] %*% diag(1.0 / (attr(Xs, 'scale')) )
    #B[, 1] <- y.mean - B[, 2:14] %*% X.mean
    
    return(t(B))
}
```


### Test your algorithm with the following lambda sequence.
```{r}
lam.seq = exp(seq (-1,-8,length.out = 80) )
myout = MyLasso (X,y,lam.seq,maxit = 100)
rownames(myout) = c("Intercept", colnames(X)) 
dim(myout)
```



### Produce a path plot for the 13 non-intercept coefficients along the lambda values in log scale.
```{r}
x.index = log(lam.seq)
beta = myout[-1, ]  # beta is a 13-by-80 matrix
matplot(x.index, t(beta),
        xlim = c(min(x.index), max(x.index)),
        lty = 1,
        xlab = "Log Lambda",
        ylab = "Coefficients",
        type="l", 
        lwd = 1)
```
```{r}
# You can add variable names to each path
# var.names = colnames(X)
# nvar = length(var.names)
# xpos = rep(min(x.index), nvar)
# ypos = beta[, ncol(beta)]
# text(xpos, ypos, var.names, cex=0.5, pos=2)
```


### Check the accuracy of your algorithm against the output from glmnet. The maximum difference between the two coefficient matrices should be less than 0.005.
```{r}
library(glmnet)
lasso.fit = glmnet(X, y, alpha = 1, lambda = lam.seq)
write.csv(as.matrix(coef(lasso.fit)), file = "Coding2_lasso_coefs.csv", row.names = FALSE)
```

```{r}
max(abs(coef(lasso.fit) - myout)) ## coeffs will be 100 times higher than expected values if we dont scale back the coeffs
```
```{r}
plot(lasso.fit, xvar = "lambda")
```

